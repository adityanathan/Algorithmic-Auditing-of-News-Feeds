{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import timeit\n",
    "import spacy\n",
    "import copy\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel, HdpModel, LdaModel, LdaMulticore\n",
    "from nltk.corpus import stopwords\n",
    "import helper as he\n",
    "\n",
    "with open('../../data/preprocessed_data/doc_indexes/aadhar.pkl','rb') as f:\n",
    "    texts,INITIAL_DOC_SIZE, DOC_TEMPORAL_INCREMENT = pickle.load(f)\n",
    "\n",
    "with open('../../data/preprocessed_data/corpus_dict/aadhar_corp.pkl', 'rb') as f:\n",
    "    data_lemmatized, _, _ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Data State to that of existing model in simulation\n",
    "data = data_lemmatized[:INITIAL_DOC_SIZE]\n",
    "id2word = Dictionary(documents=data_lemmatized)\n",
    "corpus = [id2word.doc2bow(doc) for doc in data]\n",
    "\n",
    "# Building for the first time - To be considered as the starting/existing model in simulation.\n",
    "lda = LdaMulticore(corpus, num_topics=35, id2word=id2word,\n",
    "                   workers=3, chunksize=2000, passes=10, batch=False)\n",
    "\n",
    "#Baseline Model\n",
    "corpus_baseline = copy.deepcopy(corpus)\n",
    "lda_baseline = copy.deepcopy(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Corpus Length: 13908\n",
      "MODEL NO:1\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  39\n",
      "MODEL NO:2\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  62\n",
      "MODEL NO:3\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  90\n",
      "MODEL NO:4\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  93\n",
      "MODEL NO:5\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  115\n",
      "MODEL NO:6\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  120\n",
      "MODEL NO:7\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  128\n",
      "MODEL NO:8\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  132\n",
      "MODEL NO:9\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  143\n",
      "MODEL NO:10\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  155\n",
      "MODEL NO:11\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  171\n",
      "MODEL NO:12\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  174\n",
      "MODEL NO:13\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  189\n",
      "MODEL NO:14\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  195\n",
      "MODEL NO:15\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  207\n",
      "MODEL NO:16\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  241\n",
      "MODEL NO:17\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  252\n",
      "MODEL NO:18\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  285\n",
      "MODEL NO:19\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  301\n",
      "MODEL NO:20\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  324\n",
      "MODEL NO:21\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  342\n",
      "MODEL NO:22\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  368\n",
      "MODEL NO:23\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  407\n",
      "MODEL NO:24\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  415\n",
      "MODEL NO:25\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  423\n",
      "MODEL NO:26\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  471\n",
      "MODEL NO:27\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  515\n",
      "MODEL NO:28\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  529\n",
      "MODEL NO:29\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  541\n",
      "MODEL NO:30\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  549\n",
      "MODEL NO:31\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  570\n",
      "MODEL NO:32\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  591\n",
      "MODEL NO:33\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  618\n",
      "MODEL NO:34\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  649\n",
      "MODEL NO:35\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  667\n",
      "MODEL NO:36\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  675\n",
      "MODEL NO:37\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  686\n",
      "MODEL NO:38\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  736\n",
      "MODEL NO:39\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  765\n",
      "MODEL NO:40\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  781\n",
      "MODEL NO:41\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  837\n",
      "MODEL NO:42\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  847\n",
      "MODEL NO:43\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  861\n",
      "MODEL NO:44\n",
      "MODEL DONE\n",
      "Corpus 1 Length -  874\n",
      "MODEL NO:45\n"
     ]
    }
   ],
   "source": [
    "# The loop simulates arrival of new documents in batches where batch_size is defined in DOC_TEMPORAL_INCREMENT\n",
    "doc_size = []\n",
    "positive_arr = []\n",
    "\n",
    "f2 = open('../../data/temp/aadhar_confusion.pkl', 'wb')\n",
    "\n",
    "count = 0\n",
    "doc_size_counter = INITIAL_DOC_SIZE\n",
    "print('Total Corpus Length:',len(data_lemmatized))\n",
    "for i in DOC_TEMPORAL_INCREMENT:\n",
    "    # new_docs is the list of STEP_SIZE new documents which have arrived\n",
    "    new_docs = data_lemmatized[doc_size_counter:doc_size_counter+i]\n",
    "    doc_size_counter += i\n",
    "\n",
    "    prev_corpus = copy.deepcopy(corpus)\n",
    "\n",
    "    # Converting Documents to doc2bow format so that they can be fed to models\n",
    "    corpus = [id2word.doc2bow(doc) for doc in new_docs]\n",
    "    count += 1\n",
    "\n",
    "    print('MODEL NO:'+str(count))\n",
    "    lda.update(corpus)\n",
    "    print('MODEL DONE')\n",
    "\n",
    "    prev_corpus.extend(corpus)\n",
    "    corpus = copy.deepcopy(prev_corpus)\n",
    "\n",
    "    doc_size.append(i)\n",
    "    positive_arr.append(he.calc_confusion_matrix(\n",
    "        lda_baseline, lda, corpus))\n",
    "\n",
    "    pickle.dump((positive_arr, doc_size), f2)\n",
    "\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
